{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPbX_N7zm1pW"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18bJNoWam1pW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9]{1,}\\.[0-9]{1,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.33.post1\" if v==\"2.9\" else \"0.0.32.post2\" if v==\"2.8\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyDMFnVfm1pY"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVGtfmzpm1pY",
        "outputId": "eb23cadd-d4cd-48e7-e253-c0bc8f703327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2026.1.3: Fast Llama patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n",
        "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
        "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "\n",
        "    \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\" # NEW! Llama 3.3 70B!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    # model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    model_name =   \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bZsfBuZDeCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5948b7cf-945f-4831-9d38-a023488fbf8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2026.1.3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the `Llama-3.1` format for conversation style finetunes. We use [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset in ShareGPT style. But we convert it to HuggingFace's normal multiturn format `(\"role\", \"content\")` instead of `(\"from\", \"value\")`/ Llama-3 renders multi turn conversations like below:\n",
        "\n",
        "```\n",
        "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "Hey there! How are you?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "I'm great thanks!<|eot_id|>\n",
        "```\n",
        "\n",
        "We use our `get_chat_template` function to get the correct chat template. We support `zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, phi3, llama3` and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"csv\", data_files=\"./dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSqyC_GeWIWr",
        "outputId": "10e2b74f-b78c-4285-cc79-e7328901c2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conversations': '[{\"from\": \"human\", \"value\": \"from actions import walk(obj), pick_and_place(obj, pos), open(obj), find(obj) \\\\n objects=[red_apple(fruit), banana(fruit), carrot(vegetable), broccoli(vegetable), orange(fruit), vegetable_basket, fruit_bowl] \\\\n Create python functions that do the following: move all fruits to the fruit bowl and all vegetables to the vegetable basket.\"}, {\"from\": \"gpt\", \"value\": \"def categorize_food_items():\\\\n    # Define fruits and vegetables\\\\n    fruits = [\\\\\"red_apple\\\\\", \\\\\"banana\\\\\", \\\\\"orange\\\\\"]\\\\n    vegetables = [\\\\\"carrot\\\\\", \\\\\"broccoli\\\\\"]\\\\n    \\\\n    # Move fruits to fruit bowl\\\\n    for fruit in fruits:\\\\n        if find(fruit) != \\\\\"fruit_bowl\\\\\":\\\\n            pick_and_place(fruit, \\\\\"fruit_bowl\\\\\")\\\\n        else:\\\\n            print(f\\\\\"{fruit} already in fruit_bowl, cannot move\\\\\")\\\\n    \\\\n    # Move vegetables to vegetable basket\\\\n    for vegetable in vegetables:\\\\n        if find(vegetable) != \\\\\"vegetable_basket\\\\\":\\\\n            pick_and_place(vegetable, \\\\\"vegetable_basket\\\\\")\\\\n        else:\\\\n            print(f\\\\\"{vegetable} already in vegetable_basket, cannot move\\\\\")\\\\n\\\\ncategorize_food_items()\"}]'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9CBpiISFa6C"
      },
      "source": [
        "We now use `standardize_sharegpt` to convert ShareGPT style datasets into HuggingFace's generic format. This changes the dataset from looking like:\n",
        "```\n",
        "{\"from\": \"system\", \"value\": \"You are an assistant\"}\n",
        "{\"from\": \"human\", \"value\": \"What is 2+2?\"}\n",
        "{\"from\": \"gpt\", \"value\": \"It's 4.\"}\n",
        "```\n",
        "to\n",
        "```\n",
        "{\"role\": \"system\", \"content\": \"You are an assistant\"}\n",
        "{\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
        "{\"role\": \"assistant\", \"content\": \"It's 4.\"}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import ast\n",
        "from datasets import load_dataset\n",
        "from unsloth.chat_templates import standardize_sharegpt, get_chat_template\n",
        "\n",
        "# 1. Load the CSV\n",
        "# Note: this creates a DatasetDict\n",
        "dataset = load_dataset(\"csv\", data_files=\"dataset.csv\")[\"train\"]\n",
        "\n",
        "# 2. Convert the \"conversations\" column from String to Python List\n",
        "# Because CSVs save lists as text like \"[{'from': 'human'}]\"\n",
        "def parse_json_column(example):\n",
        "    # We use json.loads or ast.literal_eval to turn the string into a list\n",
        "    if isinstance(example[\"conversations\"], str):\n",
        "        try:\n",
        "            # Try json first, fallback to literal_eval if quotes are single (')\n",
        "            example[\"conversations\"] = json.loads(example[\"conversations\"])\n",
        "        except:\n",
        "            example[\"conversations\"] = ast.literal_eval(example[\"conversations\"])\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(parse_json_column)\n",
        "\n",
        "# 3. Now standardize\n",
        "dataset = standardize_sharegpt(dataset)\n",
        "\n",
        "# 4. Apply your Llama-3.1 template\n",
        "tokenizer = get_chat_template(tokenizer, chat_template=\"llama-3.1\")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False) for convo in convos]\n",
        "    return {\"text\": texts}\n",
        "\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True)"
      ],
      "metadata": {
        "id": "JnsMx9NIhxA_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b6200bad50a148738a65dba02e6f579e",
            "f84fac3729a7433eb9830f01d2b94752",
            "59c9cb683695450a97a28465c3419b9a",
            "f1982d514f57421f97b574756cffb0e0",
            "a1d3c6c1877241499942a5ed12b72599",
            "4acaeca5ecec4647b36e91b47b936d7c",
            "0eae8f3db66343d1aaea6d603ad673c3",
            "893b1d4cf80e4a42b68a555974613ef6",
            "8a80aece26ba4d89a528673b761c2fc7",
            "2ec3b6a55999402ca9d0d27b4dd5217a",
            "9f298f0f81de46669f83778c536bf7e5"
          ]
        },
        "outputId": "899fbea2-3c5f-495c-f901-7b052b51e0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/62 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6200bad50a148738a65dba02e6f579e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPXzJZzHEgXe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "66686ea559b44265aff1cbc177e1ad2d",
            "6775700661bc458d925c05310644eaeb",
            "031d82e7906b4299b0b3042c30b037e4",
            "396d6e5508a64cd18dc5fff94b3db9de",
            "f0e095034f77453e9847f3e38a8436ba",
            "c439c70436fc41e8b03bd25e95eae406",
            "c5ca4a8c0f3041eb93b6385eaab1c96e",
            "97deceeca5b947e59edcd403a554e819",
            "fdc212d45f524019ac22a39058d9c7b8",
            "8760f18ef8f74c5aa8f4b8ef76fd0781",
            "824f7a0423f9423a942c769c11fc5235",
            "470f810f694e4dfeb70e7edf28f76ebb",
            "2dc9fee3d3fd4721a15f8cd2671a18a1",
            "a783342b67fd44358976e762e9d09803",
            "d8539dfb300e4632977956d34a771a77",
            "b82c4797fac14ec5860a1f72cab08565",
            "387864e8a6d543f0b8e18e2190b8b15b",
            "75f8953700d64211a8ff4c67494fe487",
            "6448611a375a415d89de98c1d58a112a",
            "5f4403924d3e49c8b9236eb7d125be85",
            "28ce5e62c9ec4869bddcc98b29df550e",
            "5e610213bb6f4f8e909e99b370ee3b49"
          ]
        },
        "outputId": "adca3015-1e02-4979-fdf9-2fc8c561be0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Standardizing formats (num_proc=2):   0%|          | 0/62 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66686ea559b44265aff1cbc177e1ad2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/62 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "470f810f694e4dfeb70e7edf28f76ebb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth.chat_templates import standardize_sharegpt\n",
        "dataset = standardize_sharegpt(dataset)\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndDUB23CGAC5"
      },
      "source": [
        "We look at how the conversations are structured for item 5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGFzmplrEy9I",
        "outputId": "7a443ae5-1f17-4702-d01e-d06f3916bf14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': 'from actions import walk(obj), pick_and_place(obj, pos), open(obj), find(obj) \\n objects=[cotton_shirt(clothing), wool_sweater(clothing), leather_shoes(footwear), silk_scarf(clothing), rubber_boots(footwear), wardrobe, shoe_rack] \\n Create python functions that do the following: move all clothing items to the wardrobe and all footwear to the shoe rack.',\n",
              "  'role': 'user'},\n",
              " {'content': 'def organize_clothing_and_footwear():\\n    # Define categories\\n    clothing_items = [\"cotton_shirt\", \"wool_sweater\", \"silk_scarf\"]\\n    footwear_items = [\"leather_shoes\", \"rubber_boots\"]\\n    \\n    # Move clothing to wardrobe\\n    for clothing in clothing_items:\\n        if find(clothing) != \"wardrobe\":\\n            pick_and_place(clothing, \"wardrobe\")\\n        else:\\n            print(f\"{clothing} already in wardrobe, cannot move\")\\n    \\n    # Move footwear to shoe rack\\n    for footwear in footwear_items:\\n        if find(footwear) != \"shoe_rack\":\\n            pick_and_place(footwear, \"shoe_rack\")\\n        else:\\n            print(f\"{footwear} already in shoe_rack, cannot move\")\\n\\norganize_clothing_and_footwear()',\n",
              "  'role': 'assistant'}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dataset[5][\"conversations\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfzTdMtvGE6w"
      },
      "source": [
        "And we see how the chat template transformed these conversations.\n",
        "\n",
        "**[Notice]** Llama 3.1 Instruct's default chat template default adds `\"Cutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\"`, so do not be alarmed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "vhXv0xFMGNKE",
        "outputId": "8b87c885-8029-432b-c6fc-0efc3d03eeb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nfrom actions import walk(obj), pick_and_place(obj, pos), open(obj), find(obj) \\n objects=[cotton_shirt(clothing), wool_sweater(clothing), leather_shoes(footwear), silk_scarf(clothing), rubber_boots(footwear), wardrobe, shoe_rack] \\n Create python functions that do the following: move all clothing items to the wardrobe and all footwear to the shoe rack.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\ndef organize_clothing_and_footwear():\\n    # Define categories\\n    clothing_items = [\"cotton_shirt\", \"wool_sweater\", \"silk_scarf\"]\\n    footwear_items = [\"leather_shoes\", \"rubber_boots\"]\\n    \\n    # Move clothing to wardrobe\\n    for clothing in clothing_items:\\n        if find(clothing) != \"wardrobe\":\\n            pick_and_place(clothing, \"wardrobe\")\\n        else:\\n            print(f\"{clothing} already in wardrobe, cannot move\")\\n    \\n    # Move footwear to shoe rack\\n    for footwear in footwear_items:\\n        if find(footwear) != \"shoe_rack\":\\n            pick_and_place(footwear, \"shoe_rack\")\\n        else:\\n            print(f\"{footwear} already in shoe_rack, cannot move\")\\n\\norganize_clothing_and_footwear()<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "dataset[5][\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's train our model. We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95_Nn-89DhsL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cf81c8ce5ed942708bebffd6a2050caf",
            "77483305742847a8aeb90f1544c8342a",
            "307d1b53a72b44ddb7d103968cbf8d4f",
            "349ec2f85cd141a0bde71b8dc9c85516",
            "0a2beae75c42476eab9fa32392aa617f",
            "d6ee1fd3f15c4a658260164365f807f6",
            "87ea90c10f904f71b94014dccfcb5d7f",
            "b056de1bd5fa41659df358d89aeed10e",
            "679c040801a642cda68d3b65b9f375b9",
            "970269f8c7bb4b5bb29b14ff420ae66c",
            "4119ecacb9b84ebbb22f2bf5a44a72a8"
          ]
        },
        "outputId": "7ca95dc1-1321-405b-fea3-3c3a5d076889"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=4):   0%|          | 0/62 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf81c8ce5ed942708bebffd6a2050caf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from trl import SFTConfig, SFTTrainer\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 30,\n",
        "        learning_rate = 2e-4,\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.001,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use TrackIO/WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sGp5XlG6dq"
      },
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juQiExuBG5Bt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "01dd9104c0354d7a9e13658b269f9332",
            "fdcf2823b2d942608415b3f2d171587b",
            "34fb4b45b03d4089a335f53882fd30a4",
            "7041e44a61cc43b69dc3928f07153638",
            "726743dff1174e4a83c6bab6b1d24987",
            "b1d706a7b4ad49d29561ab3ee20005ca",
            "aeb56c2b6e8843d993fd6f5b56f9d6d6",
            "7ff68b288e99456b9afe2646676c7013",
            "50e26c67093e4b0ba7fbcc0a761b03e1",
            "731965371c884574b6d0f8093db5888c",
            "03e1df21c67f48a4a5a7c130932608fd"
          ]
        },
        "outputId": "f795ab37-016a-4bfe-c0c6-bff7f8864862"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=6):   0%|          | 0/62 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01dd9104c0354d7a9e13658b269f9332"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv1NBUozV78l"
      },
      "source": [
        "We verify masking is actually done:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtsMVtlkUhja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "047981f7-26c0-41d2-b491-eed1ee5897b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nfrom actions import walk(obj), pick_and_place(obj, pos), open(obj), find(obj) \\n objects=[cotton_shirt(clothing), wool_sweater(clothing), leather_shoes(footwear), silk_scarf(clothing), rubber_boots(footwear), wardrobe, shoe_rack] \\n Create python functions that do the following: move all clothing items to the wardrobe and all footwear to the shoe rack.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\ndef organize_clothing_and_footwear():\\n    # Define categories\\n    clothing_items = [\"cotton_shirt\", \"wool_sweater\", \"silk_scarf\"]\\n    footwear_items = [\"leather_shoes\", \"rubber_boots\"]\\n    \\n    # Move clothing to wardrobe\\n    for clothing in clothing_items:\\n        if find(clothing)!= \"wardrobe\":\\n            pick_and_place(clothing, \"wardrobe\")\\n        else:\\n            print(f\"{clothing} already in wardrobe, cannot move\")\\n    \\n    # Move footwear to shoe rack\\n    for footwear in footwear_items:\\n        if find(footwear)!= \"shoe_rack\":\\n            pick_and_place(footwear, \"shoe_rack\")\\n        else:\\n            print(f\"{footwear} already in shoe_rack, cannot move\")\\n\\norganize_clothing_and_footwear()<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rD6fl8EUxnG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "b9d792a7-a6c4-4d4c-9961-d74daf8dfda7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                              def organize_clothing_and_footwear():\\n    # Define categories\\n    clothing_items = [\"cotton_shirt\", \"wool_sweater\", \"silk_scarf\"]\\n    footwear_items = [\"leather_shoes\", \"rubber_boots\"]\\n    \\n    # Move clothing to wardrobe\\n    for clothing in clothing_items:\\n        if find(clothing)!= \"wardrobe\":\\n            pick_and_place(clothing, \"wardrobe\")\\n        else:\\n            print(f\"{clothing} already in wardrobe, cannot move\")\\n    \\n    # Move footwear to shoe rack\\n    for footwear in footwear_items:\\n        if find(footwear)!= \"shoe_rack\":\\n            pick_and_place(footwear, \"shoe_rack\")\\n        else:\\n            print(f\"{footwear} already in shoe_rack, cannot move\")\\n\\norganize_clothing_and_footwear()<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3enWUM0jV-jV"
      },
      "source": [
        "We can see the System and Instruction prompts are successfully masked!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ejIt2xSNKKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e1e71c-98e5-441a-ad6a-f3df97d0bffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "8.008 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqxqAZ7KJ4oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38d2bf7a-4070-4985-c5d8-6ab211a65d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 62 | Num Epochs = 4 | Total steps = 30\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 04:17, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.706800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.668300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.731400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.586100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.488500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.390100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.355900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.374700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.284300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.243800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.242600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.188200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.185800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.225700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.204800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.215600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.128200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.144700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.141800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.181700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.114600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.123300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.097000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.119800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.085500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.072800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.140900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.075800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.119700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pCqnaKmlO1U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2229f5b0-3108-42ec-f2d3-e51ac1eb7fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275.4327 seconds used for training.\n",
            "4.59 minutes used for training.\n",
            "Peak reserved memory = 8.008 GB.\n",
            "Peak reserved memory for training = 0.0 GB.\n",
            "Peak reserved memory % of max memory = 54.325 %.\n",
            "Peak reserved memory for training % of max memory = 0.0 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = [\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"from household_robot import find(item), grab(item), deposit(item, target) \\n objects=[wine_glass, water_glass, ceramic_plate, metal_fork, soup_spoon, cloth_napkin, candle_holder, matches, framed_wedding_photo, tv_remote, magazine, newspaper, dining_table, end_table, kitchen_counter, drawer, shelf, windowsill, armchair] \\n Create a sequence of functions to perform these tasks: \\n 1. Move all items used for eating solid food from the dining table to the kitchen counter, but leave items used only for liquids. \\n 2. Find the object that creates ambiance through light and move it to the end table. Then place the object used to ignite it right next to the light source. \\n 3. Gather all paper-based reading materials from their current locations and stack them on the shelf. Place the one published most frequently on top. \\n 4. Locate the sentimental photographic item and position it on the windowsill. \\n 5. Take the fabric item from the dining table and drape it over the armchair. \\n 6. Finally, move the device used to control entertainment from wherever it is now to the end table, but ensure it's on the opposite side from the light source you placed there earlier.\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"from household_robot import find(item), grab(item), deposit(item, target) \\n objects=[coffee_mug, tea_cup, juice_glass, breakfast_plate, butter_knife, salt_shaker, pepper_shaker, sugar_bowl, potted_succulent, wall_calendar, hand_towel, sponge, breakfast_nook_table, kitchen_island, countertop, sink_edge, hook, planter_stand, waste_basket] \\n Create a sequence of functions to perform these tasks: \\n 1. Remove all vessels designed to hold beverages from the breakfast nook table and relocate them to the kitchen island. Keep track of which one is specifically for hot drinks with a handle. \\n 2. Group the paired seasoning dispensers together on the countertop. \\n 3. Find the living plant and give it a more prominent display by moving it to the planter stand. \\n 4. The sweet granular substance container should be placed next to the hot beverage vessel you identified in step 1 on the kitchen island. \\n 5. Take the cleaning tool used when wet and place it at the sink edge. \\n 6. Hang the absorbent fabric item on the hook. \\n 7. Return exactly one item to the breakfast nook table: the flat item used to hold food during the morning meal.\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"from household_robot import find(item), grab(item), deposit(item, target) \\n objects=[laptop_computer, wireless_mouse, phone_charger, smartphone, sticky_notes, pen_cup, desk_lamp, small_cactus, desk, nightstand, dresser_top, floor, chair_seat, wall_outlet, trash_can, bookend, manila_folder] \\n Create a sequence of functions to perform these tasks: \\n 1. Clear the desk of all technology items that require electricity and move them to the dresser top. Remember which one is portable communication device. \\n 2. Consolidate all writing and organizational supplies into a group on the chair seat. \\n 3. The item that provides focused illumination should be moved to the nightstand. \\n 4. Connect the charging cable to the wall outlet, then bring the portable device you identified in step 1 to rest next to its charger. \\n 5. Place the drought-resistant plant on the desk next to the architectural support item. \\n 6. The document holder should go in the trash can if it's empty, otherwise place it on the floor. \\n 7. Finally, return only the input device that works with the laptop back to the desk, positioning it where a right-handed person would naturally use it.\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"from household_robot import find(item), grab(item), deposit(item, target) \\n objects=[cutting_board, chef_knife, paring_knife, wooden_spoon, metal_spatula, olive_oil_bottle, vinegar_bottle, fresh_basil, garlic_bulb, recipe_card, kitchen_scale, stove_top, prep_counter, utensil_drawer, spice_rack, herb_pot, cutting_board_slot, cookbook_stand] \\n Create a sequence of functions to perform these tasks: \\n 1. Put away all bladed implements into the utensil drawer for safety. Note which one is larger. \\n 2. Group the two liquid ingredients together on the spice rack. \\n 3. Place the living herb into its designated pot holder. \\n 4. Position the hard surface used for chopping into its vertical storage slot. \\n 5. Move all items you would actually cook with (not cut with) to the stove top area. \\n 6. The written cooking instructions should be displayed on the cookbook stand. \\n 7. Finally, bring the aromatic bulb vegetable and place it on the prep counter next to the measuring device.\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"from household_robot import find(item), grab(item), deposit(item, target) \\n objects=[shampoo_bottle, conditioner_bottle, bar_soap, toothbrush, toothpaste, dental_floss, hand_lotion, cotton_swabs, bath_towel, hand_mirror, bathroom_counter, shower_caddy, towel_rack, medicine_cabinet, trash_bin, soap_dish, drawer_organizer] \\n Create a sequence of functions to perform these tasks: \\n 1. Move all hair care products to the shower caddy. Track which one you use first in a typical routine. \\n 2. Gather all dental hygiene items and organize them in the drawer organizer. \\n 3. The solid cleansing item should rest in its designated dish. \\n 4. Place the moisturizing product on the bathroom counter next to the reflective grooming tool. \\n 5. The cotton cleaning items should go in the medicine cabinet. \\n 6. Hang the large absorbent fabric on the towel rack. \\n 7. Finally, of the hair care products you moved in step 1, bring the one used first back to the bathroom counter temporarily.\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"from household_robot import find(item), grab(item), deposit(item, target) \\n objects=[tennis_ball, soccer_ball, jump_rope, yoga_mat, resistance_band, water_bottle, gym_towel, bluetooth_speaker, protein_bar, workout_gloves, gym_bag, equipment_rack, storage_bin, bench, floor_mat_area, wall_hook, side_table] \\n Create a sequence of functions to perform these tasks: \\n 1. Collect all spherical sports equipment and place them in the storage bin. Remember which one is larger. \\n 2. Roll up the floor exercise mat and stand it upright against the equipment rack. \\n 3. Hang the cardiovascular training rope and the elastic resistance item on the wall hook together. \\n 4. Place items worn during exercise on the bench. \\n 5. The audio device and hydration container should both go on the side table, with the device positioned to the left. \\n 6. Put the nutrition item in the gym bag. \\n 7. After completing the workout area organization, take the larger ball from step 1 back out and place it on the floor mat area.\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"from household_robot import find(item), grab(item), deposit(item, target) \\n objects=[acrylic_paint_red, acrylic_paint_blue, paintbrush_large, paintbrush_small, palette, water_cup, paint_rag, canvas, easel, art_table, supply_drawer, drying_rack, floor_cloth, chair, windowsill, palette_knife] \\n Create a sequence of functions to perform these tasks: \\n 1. Mount the blank surface onto its standing support structure. \\n 2. Arrange all color application tools on the chair in order of size, largest first. Remember this order. \\n 3. Place both pigment containers on the art table, with the cooler color on the left. \\n 4. The mixing surface and its associated scraping tool should be paired together on the windowsill. \\n 5. Position the liquid container on the supply drawer top. \\n 6. Spread the protective floor covering beneath the standing structure from step 1. \\n 7. Take the smallest tool from step 2 and place it on the mixing surface you moved in step 4. The cleaning cloth should be draped over the drying rack.\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"from household_robot import find(item), grab(item), deposit(item, target) \\n objects=[baby_bottle, pacifier, cloth_diaper, baby_wipes, diaper_cream, baby_rattle, soft_stuffed_bear, board_book, changing_pad, crib, changing_table, rocking_chair, toy_basket, supply_caddy, diaper_pail, nightlight, dresser] \\n Create a sequence of functions to perform these tasks: \\n 1. Place all diapering supplies into the caddy organizer, but leave the waterproof changing surface where it is. \\n 2. The feeding container should be positioned on the dresser top. \\n 3. Gather the two comfort items a baby would put in their mouth and place them in the crib, with the smaller one positioned in the far left corner. \\n 4. All toys meant for active play should go in the toy basket. \\n 5. The educational item with pages goes on the rocking chair seat. \\n 6. The ambient lighting device should be placed on the changing table. \\n 7. Finally, take the largest soft comfort item and place it in the crib on the opposite side from where you put the smaller mouth item in step 3.\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"from household_robot import find(item), grab(item), deposit(item, target) \\n objects=[screwdriver_phillips, screwdriver_flathead, adjustable_wrench, hammer, measuring_tape, level_tool, safety_goggles, work_gloves, wood_plank, sandpaper, paint_can, paint_tray, workbench, tool_chest, sawhorse, pegboard, floor, shelf_unit] \\n Create a sequence of functions to perform these tasks: \\n 1. Hang all handheld turning and tightening tools on the pegboard, arranged by head type. \\n 2. Personal protective equipment should be placed together on the shelf unit. \\n 3. Position the raw building material across the sawhorse to prepare it for work. \\n 4. The impacting tool and precision measuring devices should be stored together in the tool chest. \\n 5. Set up the painting supplies on the workbench with the container on the left and its paired shallow holder on the right. \\n 6. The abrasive finishing material should be placed on top of the wood material from step 3. \\n 7. Take the tool used to ensure straightness from the tool chest and place it on the workbench next to the paint setup, then move one of the protective items from step 2 to rest on top of the level tool.\"\n",
        "  }\n",
        "]"
      ],
      "metadata": {
        "id": "1kO5CH6O8gLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_responses = []\n",
        "\n",
        "# Example components\n",
        "example_user_prompt =   \"\"\"from household_robot import find(item), grab(item), deposit(item, target) \\n objects=[wine_glass, water_glass, ceramic_plate, metal_fork, soup_spoon, cloth_napkin, candle_holder, matches, framed_wedding_photo, tv_remote, magazine, newspaper, dining_table, end_table, kitchen_counter, drawer, shelf, windowsill, armchair] \\n Create a sequence of functions to perform these tasks: \\n 1. Move all items used for eating solid food from the dining table to the kitchen counter, but leave items used only for liquids. \\n 2. Find the object that creates ambiance through light and move it to the end table. Then place the object used to ignite it right next to the light source. \\n 3. Gather all paper-based reading materials from their current locations and stack them on the shelf. Place the one published most frequently on top. \\n 4. Locate the sentimental photographic item and position it on the windowsill. \\n 5. Take the fabric item from the dining table and drape it over the armchair. \\n 6. Finally, move the device used to control entertainment from wherever it is now to the end table, but ensure it's on the opposite side from the light source you placed there earlier.\"\"\"\n",
        "\n",
        "example_assistant_response = \"\"\"# Step 1: Move all items used for eating solid food from the dining table to the kitchen counter\\n# Items for eating solids: ceramic_plate, metal_fork, soup_spoon\\ngrab('ceramic_plate')\\ndeposit('ceramic_plate', 'kitchen_counter')\\ngrab('metal_fork')\\ndeposit('metal_fork', 'kitchen_counter')\\ngrab('soup_spoon')\\ndeposit('soup_spoon', 'kitchen_counter')\\n# Note: wine_glass and water_glass left on dining_table (liquids only)\\n\\n# Step 2: Move candle_holder to end_table, then matches next to it\\ngrab('candle_holder')\\ndeposit('candle_holder', 'end_table')\\ngrab('matches')\\ndeposit('matches', 'end_table')\\n\\n# Step 3: Stack paper reading materials on shelf, most frequent on top\\n# Magazine is published more frequently than newspaper\\ngrab('newspaper')\\ndeposit('newspaper', 'shelf')\\ngrab('magazine')\\ndeposit('magazine', 'shelf')\\n# Magazine now on top (published most frequently)\\n\\n# Step 4: Move sentimental photo to windowsill\\ngrab('framed_wedding_photo')\\ndeposit('framed_wedding_photo', 'windowsill')\\n\\n# Step 5: Move fabric item from dining_table to armchair\\ngrab('cloth_napkin')\\ndeposit('cloth_napkin', 'armchair')\\n\\n# Step 6: Move tv_remote to end_table opposite from candle_holder\\n# Candle_holder was placed first, so tv_remote goes on opposite side\\ngrab('tv_remote')\\ndeposit('tv_remote', 'end_table')\\n# Position: candle_holder on one side, tv_remote on opposite side\\n\"\"\"\n",
        "\n",
        "for i, conversation in enumerate(test_set):\n",
        "    # 1. Build the full history for this specific test case\n",
        "    # full_conversation = [\n",
        "    #     {\"role\": \"user\", \"content\": example_user_prompt},\n",
        "    #     {\"role\": \"assistant\", \"content\": example_assistant_response}\n",
        "    # ] + [conversation] # Changed 'conversation' to '[conversation]' to concatenate lists\n",
        "\n",
        "    full_conversation = conversation\n",
        "    # 2. Wrap 'full_conversation' in a list to satisfy the batch requirement\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        [full_conversation], # <--- Wrapped in brackets\n",
        "        tokenize = True,\n",
        "        add_generation_prompt = True,\n",
        "        return_tensors = \"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # 3. Generate\n",
        "    outputs = model.generate(\n",
        "        input_ids = inputs,\n",
        "        max_new_tokens = 2048,\n",
        "        use_cache = True,\n",
        "        temperature = 1.0,\n",
        "        min_p = 0.1\n",
        "    )\n",
        "\n",
        "    # 4. Decode\n",
        "    generated_text = tokenizer.batch_decode(outputs[:, inputs.shape[1]:], skip_special_tokens=True)[0]\n",
        "\n",
        "    all_responses.append({\n",
        "        \"output\": generated_text,\n",
        "        \"tokens_count\": outputs.shape[1] - inputs.shape[1],\n",
        "        \"input_token_count\" : inputs.shape[1]\n",
        "\n",
        "    })"
      ],
      "metadata": {
        "id": "j1h60gUKDK9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_responses\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4fy__Dv-a8_",
        "outputId": "82bde835-b9cd-4860-a513-2e906cba49a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'output': '# 1: Move solid food eating utensils\\neating_utensils = [\"metal_fork\", \"soup_spoon\"]\\nfor utensil in eating_utensils:\\n    if find(utensil)!= \"kitchen_counter\":\\n        deposit(utensil, \"kitchen_counter\")\\n    else:\\n        print(f\"{utensil} already on kitchen_counter, cannot move\")\\n\\n# 2: Move ambiance and igniter\\nambiance = \"candle_holder\"\\nigniter = \"matches\"\\ndeposit(ambiance, \"end_table\")\\nif find(igniter)!= \"end_table\":\\n    deposit(igniter, \"end_table\")\\nelse:\\n    print(f\"{igniter} already on end_table, cannot move\")\\n\\n# 3: Gather and stack paper-based reading materials\\npaper_materials = [\"magazine\", \"newspaper\"]\\nfor material in paper_materials:\\n    if find(material)!= \"shelf\":\\n        deposit(material, \"shelf\")\\n    else:\\n        print(f\"{material} already on shelf, cannot move\")\\n\\n# 4: Position sentimental photo\\nphoto = \"framed_wedding_photo\"\\nif find(photo)!= \"windowsill\":\\n    deposit(photo, \"windowsill\")\\nelse:\\n    print(f\"{photo} already on windowsill, cannot move\")\\n\\n# 5: Drape fabric\\nfabric = \"cloth_napkin\"\\nif find(fabric)!= \"armchair\":\\n    deposit(fabric, \"armchair\")\\nelse:\\n    print(f\"{fabric} already on armchair, cannot move\")\\n\\n# 6: Move entertainment controller\\ncontroller = \"tv_remote\"\\ndeposit(controller, \"end_table\")',\n",
              "  'tokens_count': 339,\n",
              "  'input_token_count': 297},\n",
              " {'output': '# 1: Remove all vessels designed to hold beverages\\nbeverage_vessels = [\"coffee_mug\", \"tea_cup\", \"juice_glass\"]\\nfor vessel in beverage_vessels:\\n    if vessel!= \"coffee_mug\":\\n        deposit(vessel, \"kitchen_island\")\\n    else:\\n        # Identify coffee_mug as hot drink vessel with handle\\n        hot_drink_vessel = \"coffee_mug\"\\n\\n# 2: Group paired seasoning dispensers together\\nseasoning_dispensers = [\"salt_shaker\", \"pepper_shaker\"]\\ndeposit(\"salt_shaker\", \"countertop\")\\ndeposit(\"pepper_shaker\", \"countertop\")\\n\\n# 3: Find living plant and move it to planter stand\\nliving_plant = \"potted_succulent\"\\ndeposit(living_plant, \"planter_stand\")\\n\\n# 4: Place sweet granular substance container near hot beverage vessel\\nsweet_substance_container = \"sugar_bowl\"\\ndeposit(sweet_substance_container, \"kitchen_island\")\\n\\n# 5: Place cleaning tool at sink edge\\ncleaning_tool = \"sponge\"\\ndeposit(cleaning_tool, \"sink_edge\")\\n\\n# 6: Hang absorbent fabric item\\nabsorbent_fabric_item = \"hand_towel\"\\ndeposit(absorbent_fabric_item, \"hook\")\\n\\n# 7: Return flat item used to hold food during morning meal\\nflat_item = \"breakfast_plate\"\\ndeposit(flat_item, \"breakfast_nook_table\")',\n",
              "  'tokens_count': 314,\n",
              "  'input_token_count': 304},\n",
              " {'output': '# 1: Clear desk of technology items requiring electricity\\n# Identify technology items that require electricity\\ntech_items = [\"laptop_computer\", \"wireless_mouse\", \"phone_charger\"]\\n# Move them to dresser top\\nfor item in tech_items:\\n    deposit(item, \"dresser_top\")\\n\\n# Remember which one is portable communication device\\nportable_device = \"smartphone\"\\n\\n# 2: Consolidate writing and organizational supplies\\n# Identify writing and organizational supplies\\nwriting_supplies = [\"sticky_notes\", \"pen_cup\"]\\norganizational_supplies = [\"manila_folder\"]\\n# Consolidate on chair seat\\nfor item in writing_supplies + organizational_supplies:\\n    deposit(item, \"chair_seat\")\\n\\n# 3: Move illumination provider\\n# Identify illumination provider\\nillumination_provider = \"desk_lamp\"\\n# Move to nightstand\\ndeposit(illumination_provider, \"nightstand\")\\n\\n# 4: Connect charging cable and bring portable device\\n# Connect charging cable\\ndeposit(\"phone_charger\", \"wall_outlet\")\\n# Bring portable device to rest next to charger\\ndeposit(portable_device, \"next to wall_outlet\")\\n\\n# 5: Place drought-resistant plant and architectural support item\\n# Identify drought-resistant plant\\ndrought_resistant_plant = \"small_cactus\"\\n# Identify architectural support item\\narchitectural_support_item = \"bookend\"\\n# Place on desk\\ndeposit(drought_resistant_plant, \"desk\")\\ndeposit(architectural_support_item, \"desk\")\\n\\n# 6: Place document holder\\n# Identify document holder\\ndocument_holder = \"manila_folder\"\\n# Check if it\\'s empty\\nif find(document_holder)!= \"trash_can\":\\n    # Not empty, place on floor\\n    deposit(document_holder, \"floor\")\\nelse:\\n    # Empty, place in trash can\\n    deposit(document_holder, \"trash_can\")\\n\\n# 7: Return input device to desk\\n# Identify input device\\ninput_device = \"wireless_mouse\"\\n# Position for right-handed person\\ndeposit(input_device, \"desk\")',\n",
              "  'tokens_count': 420,\n",
              "  'input_token_count': 295},\n",
              " {'output': '# 1: Put away bladed implements into utensil drawer for safety\\n# Identify larger blade\\nlarger_blade = \"chef_knife\"\\nbladed_implements = [\"chef_knife\", \"paring_knife\"]\\nfor blade in bladed_implements:\\n    if blade!= larger_blade:\\n        grab(blade)\\n    else:\\n        grab(blade)\\ndeposit(\"in utensil_drawer\")\\n\\n# 2: Group liquid ingredients on spice rack\\nliquid_ingredients = [\"olive_oil_bottle\", \"vinegar_bottle\"]\\ndeposit(\"on spice_rack\", liquid_ingredients)\\n\\n# 3: Place living herb in herb pot holder\\ngrab(\"fresh_basil\")\\ndeposit(\"in herb_pot\")\\n\\n# 4: Position chopping board in vertical storage slot\\ngrab(\"cutting_board\")\\ndeposit(\"in cutting_board_slot\")\\n\\n# 5: Move cooking items to stove top\\ncooking_items = [\"wooden_spoon\", \"metal_spatula\", \"kitchen_scale\"]\\ndeposit(\"on stove_top\", cooking_items)\\n\\n# 6: Display cooking instructions on cookbook stand\\ngrab(\"recipe_card\")\\ndeposit(\"on cookbook_stand\")\\n\\n# 7: Move aromatic bulb to prep counter\\ngrab(\"garlic_bulb\")\\ndeposit(\"prep_counter\")',\n",
              "  'tokens_count': 262,\n",
              "  'input_token_count': 270},\n",
              " {'output': '# 1: Move hair care products to shower caddy\\nhair_care_products = [\"shampoo_bottle\", \"conditioner_bottle\", \"bar_soap\"]\\nfor product in hair_care_products:\\n    deposit(product, \"shower_caddy\")\\n\\n# First used hair care product\\nfirst_used = \"shampoo_bottle\"\\n\\n# 2: Organize dental hygiene items\\ndental_hygiene_items = [\"toothbrush\", \"toothpaste\", \"dental_floss\"]\\ndeposit(\"drawer_organizer\", \"dentally_hygiene_items\")\\n\\n# 3: Solid cleansing item\\ndeposit(\"bar_soap\", \"soap_dish\")\\n\\n# 4: Moisturizing product and grooming tool\\ndeposit(\"hand_lotion\", \"bathroom_counter\")\\ndeposit(\"hand_mirror\", \"bathroom_counter\")\\n\\n# 5: Cotton cleaning items\\ndeposit(\"cotton_swabs\", \"medicine_cabinet\")\\n\\n# 6: Large absorbent fabric\\ndeposit(\"bath_towel\", \"towel_rack\")\\n\\n# 7: First used hair care product back to bathroom counter\\ndeposit(first_used, \"bathroom_counter\")',\n",
              "  'tokens_count': 235,\n",
              "  'input_token_count': 267},\n",
              " {'output': '# 1: Collect spherical sports equipment\\ndef collect_spherical_equipments():\\n    spherical_equipments = [\"tennis_ball\", \"soccer_ball\"]\\n    for equip in spherical_equipments:\\n        if equip == \"soccer_ball\":  # soccer ball is larger\\n            larger_ball = equip\\n        deposit(equip, \"storage_bin\")\\n\\ncollect_spherical_equipments()\\n\\n# 2: Roll up floor mat\\ndef roll_up_floor_mat():\\n    deposit(\"floor_mat_area\", \"equipment_rack\")\\n\\nroll_up_floor_mat()\\n\\n# 3: Hang cardiovascular training rope and elastic resistance item\\ndef hang_training_equipment():\\n    deposit(\"jump_rope\", \"wall_hook\")\\n    deposit(\"resistance_band\", \"wall_hook\")\\n\\nhang_training_equipment()\\n\\n# 4: Place items worn during exercise on bench\\ndef place_worn_equipment():\\n    worn_equipment = [\"workout_gloves\"]\\n    for equip in worn_equipment:\\n        deposit(equip, \"bench\")\\n\\nplace_worn_equipment()\\n\\n# 5: Arrange audio device and hydration container on side table\\ndef arrange_audio_and_hydration():\\n    deposit(\"bluetooth_speaker\", \"side_table\")\\n    deposit(\"water_bottle\", \"side_table\")\\n    # Position speaker to the left\\n    grab(\"bluetooth_speaker\")\\n    deposit(\"bluetooth_speaker\", \"side_table\", \"left\")\\n\\narrange_audio_and_hydration()\\n\\n# 6: Put nutrition item in gym bag\\ndef put_nutrition_in_bag():\\n    deposit(\"protein_bar\", \"gym_bag\")\\n\\nput_nutrition_in_bag()\\n\\n# 7: Take larger ball back out and place on floor mat\\ndef take_larger_ball_back_out():\\n    grab(\"soccer_ball\")\\n    deposit(\"soccer_ball\", \"floor_mat_area\")\\n\\ntake_larger_ball_back_out()',\n",
              "  'tokens_count': 382,\n",
              "  'input_token_count': 267},\n",
              " {'output': '# 1: Mount the blank surface onto its standing support structure\\ndeposit(\"canvas\", \"easel\")\\n\\n# 2: Arrange all color application tools on the chair in order of size, largest first\\n# Largest first: paintbrush_large, paintbrush_small\\ndeposit(\"paintbrush_large\", \"chair\")\\ndeposit(\"paintbrush_small\", \"chair\")\\n\\n# 3: Place both pigment containers on the art table, with the cooler color on the left\\n# Cooler color: blue\\n# So blue on the left, red on the right\\ndeposit(\"acrylic_paint_blue\", \"art_table\")\\ndeposit(\"acrylic_paint_red\", \"art_table\")\\n\\n# 4: The mixing surface and its associated scraping tool should be paired together on the windowsill\\n# Mixing surface: palette\\n# Associated scraping tool: palette_knife\\ndeposit(\"palette\", \"windowsill\")\\ndeposit(\"palette_knife\", \"windowsill\")\\n\\n# 5: Position the liquid container on the supply drawer top\\n# Liquid container: water_cup\\ndeposit(\"water_cup\", \"supply_drawer\")\\n\\n# 6: Spread the protective floor covering beneath the standing structure from step 1\\n# Protective floor covering: floor_cloth\\n# Standing structure: easel\\ndeposit(\"floor_cloth\", \"under easel\")\\n\\n# 7: Take the smallest tool from step 2 and place it on the mixing surface you moved in step 4\\n# Smallest tool: paintbrush_small\\n# Mixing surface: palette\\ndeposit(\"paintbrush_small\", \"palette\")\\n\\n# 8: The cleaning cloth should be draped over the drying rack\\n# Cleaning cloth: paint_rag\\ndeposit(\"paint_rag\", \"drying_rack\")',\n",
              "  'tokens_count': 352,\n",
              "  'input_token_count': 269},\n",
              " {'output': '# 1: Diapering supplies\\ndef organize_diapering_supplies():\\n    # Define diapering supplies\\n    diapering_supplies = [\"cloth_diaper\", \"baby_wipes\", \"diaper_cream\"]\\n    \\n    # Leave changing_pad where it is\\n    if \"changing_pad\" in diapering_supplies:\\n        diapering_supplies.remove(\"changing_pad\")\\n    \\n    # Deposit supplies in caddy\\n    for supply in diapering_supplies:\\n        deposit(supply, \"supply_caddy\")\\n\\n# 2: Feeding container\\ndef position_feeding_container():\\n    deposit(\"baby_bottle\", \"dresser\")\\n\\n# 3: Comfort items\\ndef gather_comfort_items():\\n    comfort_items = [\"pacifier\", \"baby_rattle\"]\\n    deposit(\"baby_rattle\", \"crib\")\\n    deposit(\"pacifier\", \"crib\")\\n    # Position pacifier in far left corner\\n    deposit(\"pacifier\", \"crib far left corner\")\\n\\n# 4: Active play toys\\ndef organize_toys():\\n    # Define active play toys\\n    active_play_toys = [\"soft_stuffed_bear\", \"board_book\"]\\n    \\n    # Deposit toys in basket\\n    for toy in active_play_toys:\\n        deposit(toy, \"toy_basket\")\\n\\n# 5: Educational item\\ndef position_educational_item():\\n    deposit(\"board_book\", \"rocking_chair\")\\n\\n# 6: Ambient lighting device\\ndef position_lighting_device():\\n    deposit(\"nightlight\", \"changing_table\")\\n\\n# 7: Soft comfort item\\ndef position_largest_comfort_item():\\n    deposit(\"soft_stuffed_bear\", \"crib opposite from pacifier\")\\n\\norganize_diapering_supplies()\\nposition_feeding_container()\\ngather_comfort_items()\\norganize_toys()\\nposition_educational_item()\\nposition_lighting_device()\\nposition_largest_comfort_item()',\n",
              "  'tokens_count': 390,\n",
              "  'input_token_count': 283},\n",
              " {'output': 'def step_1():\\n    # Handheld turning and tightening tools\\n    tools = [\"screwdriver_phillips\", \"screwdriver_flathead\"]\\n    # Arrange by head type\\n    if \"screwdriver_phillips\"!= \"screwdriver_flathead\":\\n        deposit(\"screwdriver_phillips\", \"pegboard\")\\n        deposit(\"screwdriver_flathead\", \"pegboard\")\\n    else:\\n        print(\"Cannot arrange by head type, tools have same name\")\\n\\ndef step_2():\\n    # Personal protective equipment\\n    ppe = [\"safety_goggles\", \"work_gloves\"]\\n    deposit(\"safety_goggles\", \"shelf_unit\")\\n    deposit(\"work_gloves\", \"shelf_unit\")\\n\\ndef step_3():\\n    # Raw building material\\n    material = \"wood_plank\"\\n    # Position across sawhorse\\n    deposit(\"wood_plank\", \"sawhorse\")\\n\\ndef step_4():\\n    # Impacting tool and precision measuring devices\\n    tools = [\"hammer\", \"measuring_tape\"]\\n    # Store together in tool chest\\n    deposit(\"hammer\", \"tool_chest\")\\n    deposit(\"measuring_tape\", \"tool_chest\")\\n\\ndef step_5():\\n    # Painting supplies\\n    supplies = [\"paint_can\", \"paint_tray\"]\\n    # Set up on workbench\\n    deposit(\"paint_can\", \"workbench\")\\n    deposit(\"paint_tray\", \"workbench\")\\n\\ndef step_6():\\n    # Abrasive finishing material\\n    material = \"sandpaper\"\\n    # Place on top of wood material\\n    deposit(\"sandpaper\", \"on wood_plank\")\\n\\ndef step_7():\\n    # Tool used to ensure straightness\\n    tool = \"level_tool\"\\n    # Place on workbench next to paint setup\\n    deposit(\"level_tool\", \"workbench\")\\n    # Move protective item\\n    ppe = [\"safety_goggles\", \"work_gloves\"]\\n    deposit(\"safety_goggles\", \"on level_tool\")\\n\\nstep_1()\\nstep_2()\\nstep_3()\\nstep_4()\\nstep_5()\\nstep_6()\\nstep_7()',\n",
              "  'tokens_count': 445,\n",
              "  'input_token_count': 305}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get the length of the input tokens\n",
        "input_length = inputs.shape[1]\n",
        "\n",
        "# 2. Get the total length of the output (assuming batch size 1)\n",
        "output_length = outputs.shape[1]\n",
        "\n",
        "# 3. Calculate generated tokens\n",
        "generated_tokens_count = output_length - input_length\n",
        "\n",
        "print(f\"Tokens generated: {generated_tokens_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atRN4aX-6aFX",
        "outputId": "5937caed-21c1-4dcb-cb35-43fde62607b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens generated: 445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2pEuRb1r2Vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd270cf-33eb-4323-bfc4-d4ec67e1d560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def step_1():\n",
            "    edible_items = [\"dinner_plate\", \"dessert_plate\", \"salad_bowl\", \"mug\"]\n",
            "    for item in edible_items:\n",
            "        deposit(item, \"kitchen_counter\")\n",
            "    non_decorative_eating_items = [\"kitchen_table\", \"coffee_table\"]\n",
            "    for item in non_decorative_eating_items:\n",
            "        deposit(item, \"kitchen_counter\")\n",
            "\n",
            "def step_2():\n",
            "    writing_desk_items = [\"pencil\", \"notebook\"]\n",
            "    for item in writing_desk_items:\n",
            "        if item!= \"notebook\":  # leave notebook\n",
            "            deposit(item, \"cabinet\")\n",
            "    decorative_item = \"family_portrait_photo\"\n",
            "    # leave in its original place\n",
            "\n",
            "def step_3():\n",
            "    mug_deposit = \"cabinet\"\n",
            "    coffee_mug = \"mug\"\n",
            "    # placing mug next to the last item I placed on the cabinet\n",
            "    deposit(coffee_mug, \"cabinet\")\n",
            "\n",
            "def step_4():\n",
            "    house_key = \"house_key\"\n",
            "    # take it and place it on the highest non-storage surface\n",
            "    deposit(house_key, \"bookshelf\")\n",
            "\n",
            "def step_5():\n",
            "    hardcover_book = \"hardcover_book\"\n",
            "    # place it underneath the decorative object\n",
            "    deposit(hardcover_book, \"under family_portrait_photo\")\n",
            "\n",
            "def step_6():\n",
            "    if \"coaster\" in find(\"coffee_table\"):\n",
            "        pass  # already there\n",
            "    else:\n",
            "        deposit(\"coaster\", \"coffee_table\")\n",
            "\n",
            "step_1()\n",
            "step_2()\n",
            "step_3()\n",
            "step_4()\n",
            "step_5()\n",
            "step_6()<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"from household_robot import find(item), grab(item), deposit(item, target) \\n objects=[dinner_plate, dessert_plate, salad_bowl, mug, paperback_book, hardcover_book, notebook, pencil, family_portrait_photo, house_key, coaster, vase_with_fake_flowers, kitchen_table, bookshelf, coffee_table, cabinet, kitchen_counter, drawer, sofa_cushion] \\n Create a sequence of functions to perform these tasks: \\n 1. Clear the main eating surface by moving all items meant for holding food or drink to the kitchen counter. Do not touch decorative items. \\n 2. On the surface meant for reading and relaxing, gather all items that belong to a writing desk and put them on the cabinet. However, leave the most visually prominent object that is purely for decoration in its original place. \\n 3. Now, find the item from step 1 that is specifically used for hot beverages. Place it next to the last item you placed on the cabinet in step 2. \\n 4. Retrieve the object that provides access to the home from outside. Take it and place it on the highest *non-storage* surface in the room. \\n 5. Locate the hard, flat object that is most likely to be read for leisure (not for note-taking). Pick it up and place it underneath the decorative object you intentionally left untouched in step 2. \\n 6. Finally, ensure the only remaining object on the main eating surface is the one that prevents drink rings. If it's not there, place it there.\"}\n",
        "],\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 1000,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upcOlWe7A1vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b2f753-c2d8-459a-e8fe-cbe7d9d92601"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/chat_template.jinja',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model_70b\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKX_XKs_BNZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a95820-c3d5-429d-9339-9ffbd05b6da0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Unsloth: No config file found - are you sure the `model_name` is correct?\nIf you're using a model on your local device, confirm if the folder location exists.\nIf you're using a HuggingFace online model, check if it exists.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2432988106.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastLanguageModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     model, tokenizer = FastLanguageModel.from_pretrained(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lora_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# YOUR MODEL YOU USED FOR TRAINING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/loader.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, load_in_16bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, offload_embedding, float32_mixed_precision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, qat_scheme, load_in_fp8, unsloth_tiled_mlp, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0;34m\"Please separate the LoRA and base models to 2 repos.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             )\n\u001b[0;32m--> 368\u001b[0;31m         model_types = get_transformers_model_type(\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0mpeft_config\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpeft_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth_zoo/hf_utils.py\u001b[0m in \u001b[0;36mget_transformers_model_type\u001b[0;34m(config, trust_remote_code)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m\"\"\" Gets model_type from config file - can be PEFT or normal HF \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;34mf\"Unsloth: No config file found - are you sure the `model_name` is correct?\\n\"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;34mf\"If you're using a model on your local device, confirm if the folder location exists.\\n\"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unsloth: No config file found - are you sure the `model_name` is correct?\nIf you're using a model on your local device, confirm if the folder location exists.\nIf you're using a HuggingFace online model, check if it exists."
          ]
        }
      ],
      "source": [
        "if True:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Describe a tall tower in the capital of France.\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False:\n",
        "    model.save_pretrained(\"model\")\n",
        "    tokenizer.save_pretrained(\"model\")\n",
        "if False:\n",
        "    model.push_to_hub(\"hf/model\", token = \"\")\n",
        "    tokenizer.push_to_hub(\"hf/model\", token = \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr8ovsABm1pm"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp.\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help +  <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> \n",
        "\n",
        "  This notebook and all Unsloth notebooks are licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme).\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b6200bad50a148738a65dba02e6f579e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f84fac3729a7433eb9830f01d2b94752",
              "IPY_MODEL_59c9cb683695450a97a28465c3419b9a",
              "IPY_MODEL_f1982d514f57421f97b574756cffb0e0"
            ],
            "layout": "IPY_MODEL_a1d3c6c1877241499942a5ed12b72599"
          }
        },
        "f84fac3729a7433eb9830f01d2b94752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4acaeca5ecec4647b36e91b47b936d7c",
            "placeholder": "",
            "style": "IPY_MODEL_0eae8f3db66343d1aaea6d603ad673c3",
            "value": "Map:100%"
          }
        },
        "59c9cb683695450a97a28465c3419b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_893b1d4cf80e4a42b68a555974613ef6",
            "max": 62,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a80aece26ba4d89a528673b761c2fc7",
            "value": 62
          }
        },
        "f1982d514f57421f97b574756cffb0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ec3b6a55999402ca9d0d27b4dd5217a",
            "placeholder": "",
            "style": "IPY_MODEL_9f298f0f81de46669f83778c536bf7e5",
            "value": "62/62[00:00&lt;00:00,1096.94examples/s]"
          }
        },
        "a1d3c6c1877241499942a5ed12b72599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4acaeca5ecec4647b36e91b47b936d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eae8f3db66343d1aaea6d603ad673c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "893b1d4cf80e4a42b68a555974613ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a80aece26ba4d89a528673b761c2fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ec3b6a55999402ca9d0d27b4dd5217a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f298f0f81de46669f83778c536bf7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66686ea559b44265aff1cbc177e1ad2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6775700661bc458d925c05310644eaeb",
              "IPY_MODEL_031d82e7906b4299b0b3042c30b037e4",
              "IPY_MODEL_396d6e5508a64cd18dc5fff94b3db9de"
            ],
            "layout": "IPY_MODEL_f0e095034f77453e9847f3e38a8436ba"
          }
        },
        "6775700661bc458d925c05310644eaeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c439c70436fc41e8b03bd25e95eae406",
            "placeholder": "",
            "style": "IPY_MODEL_c5ca4a8c0f3041eb93b6385eaab1c96e",
            "value": "Unsloth:Standardizingformats(num_proc=2):100%"
          }
        },
        "031d82e7906b4299b0b3042c30b037e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97deceeca5b947e59edcd403a554e819",
            "max": 62,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdc212d45f524019ac22a39058d9c7b8",
            "value": 62
          }
        },
        "396d6e5508a64cd18dc5fff94b3db9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8760f18ef8f74c5aa8f4b8ef76fd0781",
            "placeholder": "",
            "style": "IPY_MODEL_824f7a0423f9423a942c769c11fc5235",
            "value": "62/62[00:00&lt;00:00,91.38examples/s]"
          }
        },
        "f0e095034f77453e9847f3e38a8436ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c439c70436fc41e8b03bd25e95eae406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5ca4a8c0f3041eb93b6385eaab1c96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97deceeca5b947e59edcd403a554e819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdc212d45f524019ac22a39058d9c7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8760f18ef8f74c5aa8f4b8ef76fd0781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "824f7a0423f9423a942c769c11fc5235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "470f810f694e4dfeb70e7edf28f76ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dc9fee3d3fd4721a15f8cd2671a18a1",
              "IPY_MODEL_a783342b67fd44358976e762e9d09803",
              "IPY_MODEL_d8539dfb300e4632977956d34a771a77"
            ],
            "layout": "IPY_MODEL_b82c4797fac14ec5860a1f72cab08565"
          }
        },
        "2dc9fee3d3fd4721a15f8cd2671a18a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_387864e8a6d543f0b8e18e2190b8b15b",
            "placeholder": "",
            "style": "IPY_MODEL_75f8953700d64211a8ff4c67494fe487",
            "value": "Map:100%"
          }
        },
        "a783342b67fd44358976e762e9d09803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6448611a375a415d89de98c1d58a112a",
            "max": 62,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f4403924d3e49c8b9236eb7d125be85",
            "value": 62
          }
        },
        "d8539dfb300e4632977956d34a771a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28ce5e62c9ec4869bddcc98b29df550e",
            "placeholder": "",
            "style": "IPY_MODEL_5e610213bb6f4f8e909e99b370ee3b49",
            "value": "62/62[00:00&lt;00:00,683.25examples/s]"
          }
        },
        "b82c4797fac14ec5860a1f72cab08565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387864e8a6d543f0b8e18e2190b8b15b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f8953700d64211a8ff4c67494fe487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6448611a375a415d89de98c1d58a112a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f4403924d3e49c8b9236eb7d125be85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28ce5e62c9ec4869bddcc98b29df550e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e610213bb6f4f8e909e99b370ee3b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf81c8ce5ed942708bebffd6a2050caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77483305742847a8aeb90f1544c8342a",
              "IPY_MODEL_307d1b53a72b44ddb7d103968cbf8d4f",
              "IPY_MODEL_349ec2f85cd141a0bde71b8dc9c85516"
            ],
            "layout": "IPY_MODEL_0a2beae75c42476eab9fa32392aa617f"
          }
        },
        "77483305742847a8aeb90f1544c8342a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ee1fd3f15c4a658260164365f807f6",
            "placeholder": "",
            "style": "IPY_MODEL_87ea90c10f904f71b94014dccfcb5d7f",
            "value": "Unsloth:Tokenizing[&quot;text&quot;](num_proc=4):100%"
          }
        },
        "307d1b53a72b44ddb7d103968cbf8d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b056de1bd5fa41659df358d89aeed10e",
            "max": 62,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_679c040801a642cda68d3b65b9f375b9",
            "value": 62
          }
        },
        "349ec2f85cd141a0bde71b8dc9c85516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_970269f8c7bb4b5bb29b14ff420ae66c",
            "placeholder": "",
            "style": "IPY_MODEL_4119ecacb9b84ebbb22f2bf5a44a72a8",
            "value": "62/62[00:06&lt;00:00,15.51examples/s]"
          }
        },
        "0a2beae75c42476eab9fa32392aa617f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ee1fd3f15c4a658260164365f807f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87ea90c10f904f71b94014dccfcb5d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b056de1bd5fa41659df358d89aeed10e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "679c040801a642cda68d3b65b9f375b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "970269f8c7bb4b5bb29b14ff420ae66c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4119ecacb9b84ebbb22f2bf5a44a72a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01dd9104c0354d7a9e13658b269f9332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdcf2823b2d942608415b3f2d171587b",
              "IPY_MODEL_34fb4b45b03d4089a335f53882fd30a4",
              "IPY_MODEL_7041e44a61cc43b69dc3928f07153638"
            ],
            "layout": "IPY_MODEL_726743dff1174e4a83c6bab6b1d24987"
          }
        },
        "fdcf2823b2d942608415b3f2d171587b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1d706a7b4ad49d29561ab3ee20005ca",
            "placeholder": "",
            "style": "IPY_MODEL_aeb56c2b6e8843d993fd6f5b56f9d6d6",
            "value": "Map(num_proc=6):100%"
          }
        },
        "34fb4b45b03d4089a335f53882fd30a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff68b288e99456b9afe2646676c7013",
            "max": 62,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50e26c67093e4b0ba7fbcc0a761b03e1",
            "value": 62
          }
        },
        "7041e44a61cc43b69dc3928f07153638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_731965371c884574b6d0f8093db5888c",
            "placeholder": "",
            "style": "IPY_MODEL_03e1df21c67f48a4a5a7c130932608fd",
            "value": "62/62[00:01&lt;00:00,16.20examples/s]"
          }
        },
        "726743dff1174e4a83c6bab6b1d24987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1d706a7b4ad49d29561ab3ee20005ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb56c2b6e8843d993fd6f5b56f9d6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ff68b288e99456b9afe2646676c7013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e26c67093e4b0ba7fbcc0a761b03e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "731965371c884574b6d0f8093db5888c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03e1df21c67f48a4a5a7c130932608fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}